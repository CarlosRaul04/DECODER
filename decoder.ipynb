{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTAMOS LAS LIBRERÍAS Y TRAEMOS EL MODELO ELEGIDO (T5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "#Cargamos el modelo \n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos la función\n",
    "def TranslateTextSpanish(text):\n",
    "\n",
    "    translate = f\"Translate Spanish to English: {text}\"\n",
    "    #Tokenizamos\n",
    "    inputs = tokenizer(translate, return_tensors=\"pt\")\n",
    "\n",
    "    #Generamos los outputs\n",
    "    output_sequences = model.generate(\n",
    "    input_ids= inputs[\"input_ids\"],\n",
    "    max_length = 50,\n",
    "    num_beams = 5,\n",
    "    early_stopping = True #Para detener la generación cuando se alcanza la puntuación máxima\n",
    "    )\n",
    "\n",
    "    texto_salida = tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
    "\n",
    "    return texto_salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my name is Carlos Ramirez and I have 20 years. I like cats and dogs.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Creamos la petición\n",
    "input_text = \"Hola, mi nombre es carlos ramirez y tengo 20 años. Me gustan los gatos y los perros\"\n",
    "traduccion = TranslateTextSpanish(input_text)\n",
    "#Imprimimos la función\n",
    "print(traduccion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora usaremos el decoder para Resumir textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizeText(text):\n",
    "    \n",
    "    input_text = f\"summarize: {text}\"\n",
    "    #Tokenizamos\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "    # Generar el resumen\n",
    "    output_sequences = model.generate(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    max_length=150,  # Longitud máxima del resumen\n",
    "    num_beams=5,    # Beam search\n",
    "    early_stopping=True\n",
    "    )\n",
    "\n",
    "    #Decodificamos la salida\n",
    "    texto_salida = tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
    "\n",
    "    return texto_salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) es un campo de la informática que se centra en la creación de sistemas capaces de realizar tareas que normalmente requieren inteligencia humana, como reconocimiento de voz, decisiones, y traducción de idiomas. La AI se convierte en una parte integral de la tecnologa moderna y tiene aplicaciones en muchos campos, desde la medicina hasta la industria automotriz.\n"
     ]
    }
   ],
   "source": [
    "#Probamos en español y notamos que resume algunas palabras pero no es muy eficiente. \n",
    "texto = \"La inteligencia artificial (IA) es un campo de la informática que se centra en la creación de sistemas capaces de realizar tareas que normalmente requieren inteligencia humana, como el reconocimiento de voz, la toma de decisiones, y la traducción de idiomas. La IA se está convirtiendo en una parte integral de la tecnología moderna y tiene aplicaciones en numerosos campos, desde la medicina hasta la industria automotriz.\"\n",
    "resumen = summarizeText(texto)\n",
    "print(resumen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI is transforming many industries, from healthcare to automotive.\n"
     ]
    }
   ],
   "source": [
    "#Ahora probamos en ingles\n",
    "texto = \"Artificial intelligence (AI) is transforming many industries, from healthcare to automotive. AI technologies, such as machine learning and deep learning, enable computers to learn from data and perform tasks that typically require human intelligence. For instance, AI is used in medical diagnosis, helping doctors identify diseases more accurately. In the automotive industry, AI powers autonomous vehicles, allowing cars to navigate and drive themselves. Additionally, AI is enhancing customer service through chatbots that can understand and respond to customer inquiries in real-time. As AI continues to advance, it is expected to create new opportunities and challenges across various sectors.\"\n",
    "resumen = summarizeText(texto)\n",
    "print(resumen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
